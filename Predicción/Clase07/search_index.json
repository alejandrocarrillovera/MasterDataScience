[
["index.html", "Modelos Series Temporales III 1 Modelos GARCH 1.1 Bibliografía 1.2 Introducción 1.3 Volatilidad: Hechos Característicos1 1.4 Modelos GARCH 1.5 Identificación y Diagnosis 1.6 Ejemplo: IBM", " Modelos Series Temporales III © Ricardo A. Queralt MSDF: Clase 07 (Sesión 13 y 14) 1 Modelos GARCH 1.1 Bibliografía An introduction to analysis of financial data with R. Ruey S. Tsay. WILEY 2013 (Tema 5) Analysis of Financial Time Series. Third Edition RUEY S. TSAY WILEY (2010) Capítulos: 3 y 9 Mastering R for Quantitative Finance. Packt Publishing. 2015. (Tema 1) Engle y Patton (2001): “What good is a volatility model?” Quantitative Finance. http://vlab.stern.nyu.edu/ 1.2 Introducción Las series temporales de rentabilidad de activos financieros poseen unas regularidades empíricas que se conocen en la literatura especializada como hechos estilizados: Camino Aleatorio. Colas pesadas (anchas) Normalidad agregada Volatilidad no constante y agrupada (volatility cluster) 1.3 Volatilidad: Hechos Característicos1 Considerando una serie temporal de rendimientos \\(r_t\\) con \\(t=1,2,3, \\dots,T\\). La varianza muestral de los rendimientos es : \\[ \\sigma_{r_t}^2= \\frac{1}{T-1} \\sum_{t=1}^T(r_t-\\bar{r})^2 \\] donde \\(\\bar{r}=\\frac{1}{T}\\sum_{t=1}{T}r_t\\) es la media muestral. Este estadístico muestral (la varianza) se calcula con toda la muestra. Si se calcula la varianza con la primera mitad de la muestra y se compara con la varianza de la segunda mitad seguramente serán diferentes. Esto es, la varianza y su raíz cuadrada (desviación típica o volatilidad) son cambiantes en el tiempo (No son constantes). De una manera intuitiva, la volatilidad es una medida de cuánto la rentabilidad fluctúa alrededor de su media. Es una medida del riesgo. Por lo tanto, es importante, poder calcular esta volatilidad en cualquier instante, para analizar cómo varía con el tiempo y para predecir sus valores futuros. Más formalmente, sea \\(r_t=\\mu+\\epsilon_t\\) una serie temporal de los rendimientos, donde \\(\\mu\\) es la rentabilidad media o esperada y \\(\\epsilon_t\\) es el error que se expresa como: \\[ \\epsilon_t=\\sigma_t \\cdot z_t \\] donde \\(z_t\\) un ruido blanco gaussiano de media cero y \\(\\sigma_t\\) es una volatilidad cambiante en el tiempo que definimos como heterocesdasticidad condicional. De tal forma, que la volatilidad futura se puede predecir basándose en su volatilidad pasada y otras variables condicionantes. Con el fin de realizar el análisis de la volatilidad, es necesario especificar esta dependencia, para lo que se utilizan los modelos del tipo de Heteroscedasticidad condicional autorregresiva generalizada (GARCH). Algunos fenómenos se observan sistemáticamente en casi todas las series temporales de rentabilidad. Un buen modelo de heteroscedasticidad condicional debe ser capaz de captar la mayoría de estos hechos. Los hechos estilizados más conocidos en el análisis de la volatilidad son: Los clusters de volatilidad: La volatilidad es más probable que sea alta en el momento t si también fue alta en el momento t-1. Es decir, un shock en el momento t-1 aumenta no sólo la varianza en el tiempo t-1, sino también la varianza en el tiempo t. Así, los mercados son más volátiles en algunos períodos, y son más tranquilo que en otros. Las volatilidades están agrupados en el tiempo. Los modelos de tipo GARCH capturar este efecto. De hecho, estos modelos son precisamente una forma de especificar cómo la volatilidad en el tiempo t depende de la volatilidad pasada (y posiblemente otras variables condicionales). Colas gruesas (anchas): Las rentabilidades generalmente presentar colas gruesas, también conocido como el exceso de curtosis o leptokurtosis. Es decir, su curtosis es generalmente mayor que tres, recordar que ese es el valor de la curtosis de una variable aleatoria gaussiana o normal. Para comprobar este comportamiento se puede realizar un contraste Jarque-Bera, para verificar de forma conjunta tanto si la distribución es simétrica y si la distribución presenta curtosis igual a tres y es normal. Si los rendimientos son de cola ancha, la probabilidad de tener eventos extremos (rendimientos muy altos o muy bajos) es más alta de lo que sería en el caso normal. Asimetría: Hay un hecho estilizado que el modelo GARCH normal no es capaz de capturar, que es el hecho observado empíricamente que los shocks negativos en el momento t-1 tienen un mayor impacto en la variación en el tiempo t que los shocks positivos. Sin embargo, el modelo GARCH puede ser fácilmente modificado para capturar esta asimetría. Ejemplos de estas generalizaciones son los GARCH Umbral (TGARCH), el asimétrico GARCH (AGARCH) y la exponencial GARCH (EGARCH). Esta asimetría se llama efecto de influencia/apalancamiento (leverage) debido a que el aumento del riesgo proviene de la creciente influencia generada por un shock negativo. 1.4 Modelos GARCH Para construir un modelo de volatilidad para los rendimientos de un activo debemos tener en cuenta cuatro etapas: Especificar un modelo para la media, si es necesario estimar un modelo ARIMA para modelizar la dependencia lineal, de tal forma que el termino de error sea ruido blanco (media cero y sin autocorrelación): \\[ \\text{ECUACIÓN DE LA MEDIA}\\\\ r_t=\\mu+\\epsilon_t \\equiv \\text{Modelo con Constante} \\\\ r_t=\\mu+ARIMA(p,d,q)+\\epsilon_t \\equiv \\text{Modelo con ARIMA} \\] Usar los residuos de la ecuación de la media para verificar efectos ARCH. Especificar un modelo GARCH y estimar conjunto el modelo de la media y de la volatilidad. Verificar que el modelo ajustado y reestimar si es necesario. 1.4.1 Definición Modelo GARCH Sea \\(r_t=\\mu+\\epsilon_t\\) una serie temporal de los rendimientos, donde \\(\\mu\\) es la rentabilidad media o esperada y \\(\\epsilon_t\\) es el error que se expresa como: \\[ \\epsilon_t=\\sigma_t \\cdot z_t \\] donde \\(z_t\\) un ruido blanco gaussiano de media cero y se dice que \\(\\epsilon_t \\sim GARCH(p,q)\\) si: \\[ \\sigma_t^2=\\omega+\\alpha_1\\epsilon_{t-1}^2+\\dots+\\alpha_p\\epsilon_{t-p}^2+\\beta_1\\sigma_{t-1}^2+\\dots+\\beta_q\\sigma_{t-q}^2 \\] Los modelos se pueden seleccionar utilizando un criterio de información (AIC, BIC o SIC). Como caso particular se encuentran: \\[ \\text{ARCH(p)}\\\\ \\sigma_t^2=\\omega+\\alpha_1\\epsilon_{t-1}^2+\\dots+\\alpha_p\\epsilon_{t-p}^2\\\\ \\\\ \\text{GARCH(1,1)}\\\\ \\sigma_t^2=\\omega+\\alpha_1\\epsilon_{t-1}^2+\\alpha_p\\epsilon_{t-p}^2+\\beta_1\\sigma_{t-1}^2 \\] El GARCH(1,1) es el modelo mas utilizado, en realidad es un ARMA(1,1) sobre la varianza de los errores. En este modelo se debe cumplir que \\(\\alpha_1+\\beta_1&lt;1\\), caracterizándose la volatilidad por revertir a la media, fluctuando alrededor la raíz de la varianza incondicional: \\[ \\sigma^2\\equiv Var(r_t)=\\frac{\\omega}{1-\\alpha_1-\\beta_1} \\] Además, debe cumplirse que \\(\\omega,\\alpha_1,\\beta_1&gt;0\\). En cuanto a la predicción de la varianza horizonte h será: \\[ \\hat \\sigma _{T + h}^2 = \\hat \\omega + \\left( {\\hat{\\alpha _1} + \\hat {\\beta _1}} \\right)\\hat \\sigma _{T + h - 1}^2 \\] En cuanto a la volatilidad compuesta será: \\[ {\\hat \\sigma _{T + 1:T + h}} = \\sqrt {\\sum\\limits_{i = 1}^h {\\hat \\sigma _{T + i}^2} } \\to \\sqrt h \\sqrt {\\frac{{\\hat \\omega }}{{1 - {{\\hat \\alpha }_1} - {{\\hat \\beta }_1}}}} \\] Otros modelos son: 1.5 Identificación y Diagnosis Las herramientas para la identificación y diagnosis del modelo GARCH son: Gráfico de los rendimientos al cuadrado o valor absoluto. ACF y PACF de los rendimientos al cuadrado o valor absoluto. Test Ljung-Box de los rendimientos al cuadrado o valor absoluto. Test de Multiplicadores de Langrage de Engle (LM), donde la hipótesis nula es de no GARCH. \\[ \\begin{gathered} \\,\\varepsilon _t^2 = {\\alpha _0} + {\\alpha _1}\\varepsilon _{t - 1}^2 + \\cdots + {\\alpha _m}\\varepsilon _{t - m}^2 + error \\hfill \\\\ {H_0}:\\,{\\alpha _0} = {\\alpha _1} = \\cdots = {\\alpha _m} = 0 \\hfill \\\\ {H_1}:{\\alpha _i} \\ne 0 \\hfill \\\\ \\end{gathered} \\] 1.6 Ejemplo: IBM # Volatility #Stylized facts and GARCH models #(c)Ricardo A. Queralt # References: # Tsay(2013) # library(&quot;quantmod&quot;) #Package to download financials historical data library(forecast) library(&quot;fGarch&quot;) #funciones archTest &lt;- function(rtn,m=10){ # Perform Lagrange Multiplier Test for ARCH effect of a time series # rtn: time series # m: selected AR order # TSAY(2013) y=(rtn-mean(rtn))^2 T=length(rtn) atsq=y[(m+1):T] x=matrix(0,(T-m),m) for (i in 1:m){ x[,i]=y[(m+1-i):(T-i)] } md=lm(atsq~x) summary(md) } ###FIN FUNCIONES #Yahoo ticker (stock or index) sSymbol=&quot;IBM&quot; #get data from yahoo mData&lt;-getSymbols(sSymbol ,from=&quot;1990-01-01&quot;,to=&quot;2016-09-30&quot;,auto.assign=FALSE) #Define workdata xData=Ad(mData) #Calculate Daily Arithmetic Return dRentCont=dailyReturn(xData,type=&#39;log&#39;,leading=FALSE) #Exclude NA (First data) dRentCont=na.exclude(dRentCont) plot.zoo(cbind(xData,dRentCont),main=paste(sSymbol,&quot; y Rentabilidad&quot;),xlab=&quot;años&quot;,ylab=c(&quot;Precio&quot;,&quot;rentabilidad&quot;)) grid(lwd=2) #Volatilidad GARCH #Plot return squared plot.zoo(cbind(Ad(mData),dRentCont,dRentCont^2),main=paste(sSymbol,&quot; y Rentabilidad&quot;),xlab=&quot;años&quot;,ylab=c(&quot;Precio&quot;,&quot;rentabilidad&quot;,&quot;Volatilidad&quot;)) #testing mean t.test(dRentCont) #ACF &amp; PACF # VolProxy=abs(dRentCont) # absolute value VolProxy=dRentCont^2 #squared #ACF y PACF tsdisplay(VolProxy) #Ljung-Box Test Box.test(VolProxy,lag=10, type=&quot;Lj&quot;) Box.test(VolProxy,lag=20, type=&quot;Lj&quot;) Box.test(VolProxy,lag=40, type=&quot;Lj&quot;) #LM test archTest(dRentCont,20) #ARCH(1) m1=garchFit(~1+garch(1,0),data=dRentCont,trace=F) # Fit an ARCH(1) model summary(m1) resi=residuals(m1,standardize=T) #residuals resi=xts(resi,order.by=index(dRentCont)) #residuals as xts tsdisplay(resi^2) #acf pacf residuals #GARCH(1,1) m2=garchFit(~1+garch(1,1),data=dRentCont,trace=F) # Fit an GARCH(1,1) model summary(m2) resi=residuals(m2,standardize=T) #residuals resi=xts(resi,order.by=index(dRentCont)) #residuals as xts tsdisplay(resi^2) #acf pacf residuals plot(m2) #t-student m3=garchFit(~1+garch(1,1),data=dRentCont,trace=F,cond.dist=&quot;std&quot;) summary(m3) plot(m3) v1=volatility(m3) # Obtain volatility v1=xts(v1,order.by=index(dRentCont)) # volatility as XTS plot(sqrt(252)*v1) resi=residuals(m3,standardize=T) # Standardized residuals resi=xts(resi,order.by=index(dRentCont)) # Standardized residuals as XTS tsdisplay(resi^2) #acf pacf residuals plot(resi) predict(m3) #forecast volatility predict(m3, n.ahead = 10, plot=TRUE, crit_val=2) #plot with 2*standard error predict(m3,n.ahead=20,plot=TRUE,conf=.9,nx=100) # plot 100 data with 90% confidence http://vlab.stern.nyu.edu/doc/1?topic=apps↩︎ "],
["modelos-var.html", "2 Modelos VAR 2.1 Bibliografía 2.2 Vectores Autorregresivos 2.3 Ejemplo 1 2.4 Ejemplo 2", " 2 Modelos VAR 2.1 Bibliografía Analysis of Financial Time Series. Third Edition RUEY S. TSAY WILEY (2010) Capítulos: 9 2.2 Vectores Autorregresivos Una limitación con los modelos que hemos considerado hasta ahora es que imponen una relación unidireccional. La variable dependiente está influenciada por las variables predictoras (independientes, pero no viceversa. Sin embargo, hay muchos casos en los que también se debe permitir lo contrario, donde todas las variables se afectan entre sí. Tales relaciones de retroalimentación (bidirecionalidad) se modelizancon los vectores autorregresivos (VAR). En un VAR, todas las variables son tratadas simétricamente. Todos ellos son modelizados como si se influyeran entre sí por igual. En una terminología más formal, todas las variables son ahora tratadas como “endógenas”. Para significar esto ahora cambiamos la notación y escribimos todas las variables como y’s: \\[ y_{1,t}, y_{2,t} \\] Un modelo VAR es una generalización del modelo AR(p) para preddecir un conjunto de variables; Es decir, un vector de series temporales. Comprende una ecuación por variable considerada en el sistema. El lado derecho de cada ecuación incluye una constante y retarda todas las variables del sistema. Para simplificar, consideraremos un VAR de dos variables con un retardo. Escribimos un VAR(1) bidimensional como: \\[ \\begin{align*} y_{1,t} &amp;= c_1+\\phi_{11,1}y_{1,t-1}+\\phi_{12,1}y_{2,t-1}+e_{1,t} \\\\ y_{2,t} &amp;= c_2+\\phi_{21,1}y_{1,t-1}+\\phi_{22,1}y_{2,t-1}+e_{2,t} \\end{align*} \\] Si las series son estacionarias, las predecimos mediante el ajuste directo de un VAR a los datos (conocido como “VAR en niveles”). Si las series son no estacionarias, tomamos diferencias para hacerlas estacionarias y luego nos adaptamos a un modelo VAR (conocido como “VAR en diferencias”). La otra posibilidad es que las series pueden ser no estacionarias pero están cointegradas, lo que significa que existe una combinación lineal de ellas que es estacionaria. En este caso se debe incluir una especificación VAR que incluya un mecanismo de corrección de errores (usualmente denominado modelo de corrección de errores vectorial VECM) y se deben usar métodos alternativos de estimación para estimar los mínimos cuadrados. Las predicciones se generan a partir de un VAR de una manera recursiva. El VAR genera predicciones para cada variable incluida en el sistema. Hay dos decisiones que uno tiene que tomar al usar un VAR para ppredecir: cuántas variables (denotadas por K) deben ser incluidos en el sistema cuántos retrasos (denotados por p) deben ser incluidos en el sistema. El número de coeficientes a estimar en un VAR es igual a \\(K + pK^2\\) o \\((1 + pK)\\) por ecuación. Por ejemplo, para un VAR con K = 5 (5 Variables) y p = 3 (3 retardos), hay 16 coeficientes por ecuación que hacen para un total de 80 coeficientes que estimar. Cuanto más coeficientes se estimen, mayor será el error de estimación que ingresa en ela predicción. En la práctica, es habitual mantener K pequeñas e incluir sólo variables que están correlacionadas entre sí y, por lo tanto, útiles para predecirse entre sí. Los criterios de información (fundamentalmente BIC) se usan comúnmente para seleccionar el número de retrasos a incluir. Una crítica que los VAR enfrentan es que no tienen en cuenta la teoría: No se basan en alguna teoría económica que impone una estructura teórica a las ecuaciones. Se supone que cada variable influye en todas las demás variables del sistema, lo que hace muy difícil la interpretación directa de los coeficientes estimados. A pesar de esto, los VARs son útiles en varios contextos: pronosticar una colección de variables relacionadas donde no se requiere una interpretación explícita de los coeficientes probar si una variable es útil para pronosticar otra (causalidad de Granger), análisis de respuesta de impulso, donde la respuesta de uno Variable a un cambio súbito pero temporal en otra variable se analiza, descomposición de la varianza del error de pronóstico, donde la proporción de la varianza de pronóstico de una variable se atribuye al efecto de otras variables. 2.3 Ejemplo 1 library(quantmod) library(vars) ## Leer datos tef=getSymbols(&quot;Tef.mc&quot;,env=NULL) ibex=getSymbols(&quot;^ibex&quot;,env=NULL) # Generar rentabilidad mensual rtef=monthlyReturn(tef[,6]) ribex=monthlyReturn(ibex[,6]) #generar vector vY=cbind(rtef,ribex) colnames(vY)=c(&quot;TEF&quot;,&quot;IBEX&quot;) vY=na.omit(vY) #Seleccionar modelo VARselect(vY) #estimar model.var=VAR(vY) summary(model.var) model.var1=VAR(vY,type=&quot;none&quot;) summary(model.var1) #causalidad de granger causality(model.var1) #respuesta al impulso model.ri=irf(model.var1) model.ri plot(model.ri) ##prediccion predict(model.var1, n.ahead = 8, ci = 0.95) 2.4 Ejemplo 2 library(quantmod) library(vars) getSymbols(&#39;MSFT&#39;, from=&#39;2004-01-02&#39;, to=&#39;2014-03-31&#39;) getSymbols(&#39;SNP&#39;, from=&#39;2004-01-02&#39;, to=&#39;2014-03-31&#39;) getSymbols(&#39;DTB3&#39;, src=&#39;FRED&#39;) DTB3.sub &lt;- DTB3[&#39;2004-01-02/2014-03-31&#39;] MSFT.ret &lt;- diff(log(Ad(MSFT))) SNP.ret &lt;- diff(log(Ad(SNP))) dataDaily &lt;- na.omit(merge(SNP.ret,MSFT.ret,DTB3.sub), join=&#39;inner&#39;) SNP.M &lt;- to.monthly(SNP.ret)$SNP.ret.Close MSFT.M &lt;- to.monthly(MSFT.ret)$MSFT.ret.Close DTB3.M &lt;- to.monthly(DTB3.sub)$DTB3.sub.Close var1 &lt;- VAR(dataDaily, lag.max=4, ic=&quot;AIC&quot;) summary(var1) var1 VARselect(dataDaily,lag.max=4) plot(var1) #Diagram of fit and residuals for each variables coef(var1) #concise summary of the estimated variables residuals(var1) #list of residuals (of the corresponding ~lm) fitted(var1) #list of fitted values var.pred &lt;- predict(var1, n.ahead=10, ci=0.95) Phi(var1) #coefficient matrices of VMA representation var.irf &lt;- irf(var1) plot(var.irf) "],
["cointegración.html", "3 Cointegración 3.1 PROCEDIMIENTO DE ESTIMACIÓN ANTE SERIES TEMPORALES NO ESTACIONARIAS 3.2 Estimación 3.3 Ejemplo Pair Trading", " 3 Cointegración El análisis de series temporales se encuentra con un problema al medir las relaciones entre aquellas variables que tienen una tendencia temporal. Este problema puede llegar a que se consideren significativas relaciones completamente espurias. Las variables que tienen una tendencia temporal definida se denominan “no estacionarias”. Las estimaciones de regresiones con variables no estacionarias son espurias salvo que estas estén cointegradas. Dos variables no estacionarias cointegradas son aquellas cuyos residuos son estacionarios. Si los residuos son estacionarios las estimaciones de variables no estacionarias son superconsistentes. 3.1 PROCEDIMIENTO DE ESTIMACIÓN ANTE SERIES TEMPORALES NO ESTACIONARIAS El algoritmo de estimación es: si las series son estacionarias Se estima por los procedimientos habituales (MCO o GLM) si las series son no estacionarias de orden distinto: Formalmente se dice que la serie temporal \\(y_t\\) tiene raíz de orden d \\(y_t \\sim I(d)\\) cuando \\(y_t\\) se transforma en una serie estacionaria al ser diferenciada d veces. Si las series son no estacionarias de orden distinto entre sí, NO puede estimarse la relación entre ambas. si las series son no estacionarias del mismo orden pero no están cointegradas. NO puede estimarse la relación entre ambas porque la regresión es espuria. Se puede intentar estacionalizar las series (mediante alguna operación, logaritmos o diferencias o ratios con otras variables) o hacer una regresión por primeras diferencias (el resultado nos indicará si la correlación existe o no. si las series son no estacionarias pero están cointegradas Se puede pasar la regresión habitual (MCO GLM) para estimar los efectos a largo plazo y el modelo de corrección de errores para estimar los efectos a corto plazo. 3.2 Estimación El método de Engle y Granger tiene tres fases: estimación de la estacionariedad de las series; pruebas de cointegración y método de corrección de errores. 3.2.1 Estacionariedad visual y Correlograma Dickey-Fuller (Dickey-Fuller, 1979, 1984; Said-Dickey 1984) y Dickey-Fuller aumentada. La H0 es que es no estacionaria (I(1)) El test puede realizarse en tres versiones sin constante ni tendencia o con alguna de las dos. PERO ES ACONSEJABLE HACERLO SIEMPRE UTILIZANDO LA TENDENCIA, PARA CORREGIR ESTE EFECTO SI EXISTE 3.2.2 Pruebas de Cointegración Supongamos que dos variables temporales \\(x_t\\) e \\(y_t\\) son estacionarias de orden 1 (es decir son I(1)). Se dice que dichas variables están cointegradas cuando puede practicarse una regresión linealy los errores son I(0): \\[ y_t = a + bx_t + u_t \\] 3.2.3 Modelo de corrección de errores. (ECM) Como una extensión del modelo, si las variables están cointegradas se pueden utilizar los residuos para corregir los errores y estimar también los efectos a corto plazo. El modelo a estimar se denomina de corrección de errores y su especificación es: \\[ y_t-y_{t-1} = \\beta (x_t–x_{t-1}) + \\gamma (y_{t-1} – a – b x_{t-1}) + \\epsilon_t \\] Donde \\[ \\text{Modelo de Corrección de Error es:}\\\\ \\gamma (y_{t-1} – a – b x_{t-1}) = \\gamma u_{t-1} \\] es el mecanismo de corrección, \\(b\\) es la influencia a largo plazo de x sobre y, \\(\\beta\\) es la estimación de la influencia, a corto plazo de x sobre y. El modelo también suele escribirse: \\[ \\Delta y_t = \\beta (\\Delta x_t) + \\gamma (u_{t-1}) + \\epsilon_t \\] 3.3 Ejemplo Pair Trading require(devtools) install_version(&quot;PairTrading&quot;, version = &quot;1.1&quot;, repos = &quot;http://cran.us.r-project.org&quot;) library(PairTrading) #load library library(PairTrading) #load sample stock price data data(stock.price) #select 2 stocks price.pair &lt;- stock.price[,1:2][&quot;2008-12-31::&quot;] adf.test(price.pair[,1],k=0) adf.test(price.pair[,2],k=0) adf.test(price.pair[,1],k=6) adf.test library(urca) test_1&lt;-ur.df(price.pair[,1],type=&quot;none&quot;,selectlags=&quot;AIC&quot;,lags=10) summary(test_1) test_2&lt;-ur.df(price.pair[,1],type=&quot;trend&quot;,selectlags=&quot;AIC&quot;,lags=10) summary(test_2) #Estimate parameters &amp; plot spread reg &lt;- EstimateParameters(price.pair, method = lm) str(reg) plot(reg$spread) #check stationarity IsStationary(reg$spread, 0.1) #estimate parameters for back test params &lt;- EstimateParametersHistorically(price.pair, period = 180) #create &amp; plot trading signals signal &lt;- Simple(params$spread, 0.05) barplot(signal,col=&quot;blue&quot;,space = 0, border = &quot;blue&quot;,xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) par(new=TRUE) plot(params$spread) #Performance of pair trading return.pairtrading &lt;- Return(price.pair, lag(signal), lag(params$hedge.ratio)) plot(100 * cumprod(1 + return.pairtrading)) "],
["cambio-de-regimen-hidden-markov-models-regime-switching.html", "4 Cambio de Regimen (Hidden Markov Models - Regime switching) 4.1 Ejemplo", " 4 Cambio de Regimen (Hidden Markov Models - Regime switching) Un modelo de cambio de régimen combina dos o más conjuntos de parámetros en un sistema y calcula la verosimilitud de cada régimen en cada momento del tiempo. Definimos un modelo de Markov-Switching de dos estados que permite diferentes medias en el crecimiento: \\[ \\nabla y_t=\\left\\{ \\begin{array}{cc} \\alpha_1 &amp; s(t)=1 \\\\ \\alpha_2 &amp; s(t)=2 \\end{array} \\right. \\] Donde s(t) denota el estado de la variable en el momento t. El estado s(t) se determina por una cadena de Markov, la cual depende asimismo de una matriz de transición. Esta matriz muestra la probabilidad de que un estado particular sea seguido por otro estado particular. Además, las probabilidades de transición se suponen estacionarias en el tiempo. \\[ \\left[\\begin{array}{cc} p_{11} &amp; p_{21} \\\\ p_{12} &amp; p_{22} \\end{array} \\right] = \\left[\\begin{array}{cc} p_{11} &amp; 1-p_{22} \\\\ 1-p_{11} &amp; p_{22} \\end{array} \\right] \\] Se pueden calcular las probabilidades estacionarias (ergódicas, no condicionadas): \\[ \\pi=\\left[\\begin{array}{c} \\frac{1-p_{22}}{2-p_{11} - p_{22}} \\\\ \\frac{1-p_{11}}{2-p_{11} - p_{22}} \\end{array} \\right] \\\\ P\\{s(t)=1\\}=\\frac{1-p_{22}}{2-p_{11} - p_{22}} \\] La estimación de los modelos se realiza mediante un algoritmo EM de máxima-verosimilitud 4.1 Ejemplo library(depmixS4) library(TTR) library(ggplot2) library(reshape2) library(xts) library(extrafont) library(quantmod) ### Leer datos ibex=getSymbols(&quot;^ibex&quot;,env=NULL) ibex=na.omit(ibex) #crear XTS mData=ibex$IBEX.Adjusted colnames(mData)=c(&quot;Close&quot;) #crear XTS semanal semanal=function(mData){ aa=seq.Date(as.Date(min(index(mData))),length.out=2+as.numeric(as.Date(max(index(mData)))-as.Date(min(index(mData)))),by=&quot;1 days&quot;) bb=xts(rep(NA,length(aa)),aa) cc=bb[time(bb[.indexwday(bb)==5])] dd=sapply(1:(length(cc)-1), function(x) last(mData[seq.Date(as.Date(time(cc[x])),as.Date(time(cc[x+1])),1)])) coredata(cc[2:(length(cc))])=dd return(cc) } mDataLR=semanal(mData) #Añadir Rentabilidad colnames(mDataLR)=c(&quot;Close&quot;) # mDataLR$Rentabilidad &lt;- log(mDataLR$Close) - lag(log(mDataLR$Close),k=2) #elimnar NAs mDataLR &lt;- na.exclude(mDataLR) #Transformar XTS en DF mDataLRdf &lt;- data.frame(mDataLR) #Poner la fecha que esta en el nombre de la fila como columna de fecha con formato mDataLRdf$Date &lt;-as.Date(row.names(mDataLRdf),&quot;%Y-%m-%d&quot;) #definir modelo HHM de markov con 2 estados. Rentabilidad en función de la constante mod &lt;- depmix(Rentabilidad ~ 1, family = gaussian(), nstates = 2, data = mDataLR) set.seed(1) # Estimar fm2 &lt;- fit(mod, verbose = FALSE) #Resumen de resultados summary(fm2) print(fm2) # Compute probability of being in each state probs &lt;- posterior(fm2) mDataLRdf$pBull &lt;- probs[,2] mDataLRdf$pBear &lt;- probs[,3] mDataLRdf$pState &lt;- probs[,1] #Nombre a la Primera columna #colnames(mDataLRdf$logret)=c(&quot;Rentabilidad&quot;) colnames(mDataLRdf)[1]=nameStock #Crear df para ggplot2 df &lt;- melt(mDataLRdf[,c(1,2,3,4,5,6)],id=&quot;Date&quot;,measure=c(nameStock,&quot;Rentabilidad&quot;,&quot;pBull&quot;,&quot;pBear&quot;,&quot;pState&quot;)) ##Gráfico Probabilidad positivoColor=subset(df,df$variable ==&quot;Rentabilidad&quot;) pColor=ifelse(positivoColor$value &gt;=0, &quot;blue&quot;, &quot;red&quot;) f &lt;- ggplot()+ geom_step(data=subset(df,df$variable ==nameStock),aes(Date, value))+ geom_linerange(data=positivoColor,aes(Date, value,ymin=0,ymax=value),color = pColor)+ geom_linerange(data=subset(df,df$variable ==&quot;pBull&quot;),aes(Date, value,ymin=0,ymax=value),color=&quot;cornflowerblue&quot;)+ facet_grid(variable ~., scales = &quot;free&quot;, as.table = TRUE) + scale_x_date(date_breaks = &quot;1 years&quot;,date_labels = &quot;%y&quot;)+ theme_bw() + theme(panel.spacing = unit(0,&quot;lines&quot;), axis.title.x = element_blank(), axis.title.y = element_blank(), strip.background = element_rect(colour=&quot;black&quot;, fill=&quot;white&quot;))+ ggtitle(&quot;Grafico de Estados&quot;) f #####ESTADOs f &lt;- ggplot()+ geom_step(data=subset(df,df$variable ==nameStock),aes(Date, value))+ geom_linerange(data=positivoColor,aes(Date, value,ymin=0,ymax=value),color = pColor)+ geom_linerange(data=subset(df,df$variable ==&quot;pBull&quot;),aes(Date, value,ymin=0,ymax=value),color=&quot;cornflowerblue&quot;)+ geom_step(data=subset(df,df$variable ==&quot;pState&quot;),aes(Date, 2-value),color=&quot;cornflowerblue&quot;,size=1)+ facet_grid(variable ~., scales = &quot;free&quot;, as.table = TRUE) + scale_x_date(date_breaks = &quot;1 years&quot;,date_labels = &quot;%y&quot;)+ theme_bw() + theme(panel.spacing = unit(0,&quot;lines&quot;), axis.title.x = element_blank(), axis.title.y = element_blank(), strip.background = element_rect(colour=&quot;black&quot;, fill=&quot;white&quot;))+ ggtitle(&quot;Ciclos del IBEX35: Alcista vs Bajista&quot;)+labs(caption = &quot;Ibex35 Hidden Markov Model two states: rentabilidades quincenales&quot;) f "]
]
